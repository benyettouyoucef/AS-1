{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#An-Introduction-to-Torch-Framework\" data-toc-modified-id=\"An-Introduction-to-Torch-Framework-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>An Introduction to Torch Framework</a></div><div class=\"lev2 toc-item\"><a href=\"#Context\" data-toc-modified-id=\"Context-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Context</a></div><div class=\"lev2 toc-item\"><a href=\"#In-a-nutshell-:\" data-toc-modified-id=\"In-a-nutshell-:-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>In a nutshell :</a></div><div class=\"lev1 toc-item\"><a href=\"#Implementations\" data-toc-modified-id=\"Implementations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Implementations</a></div><div class=\"lev2 toc-item\"><a href=\"#Loading-the-required-modules\" data-toc-modified-id=\"Loading-the-required-modules-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Loading the required modules</a></div><div class=\"lev2 toc-item\"><a href=\"#Initiallizing-default-parameters\" data-toc-modified-id=\"Initiallizing-default-parameters-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Initiallizing default parameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Linear-Models---Overview\" data-toc-modified-id=\"Linear-Models---Overview-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Linear Models - Overview</a></div><div class=\"lev3 toc-item\"><a href=\"#Linear-Models-:-definition\" data-toc-modified-id=\"Linear-Models-:-definition-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Linear Models : definition</a></div><div class=\"lev3 toc-item\"><a href=\"#Fitting-linear-model\" data-toc-modified-id=\"Fitting-linear-model-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Fitting linear model</a></div><div class=\"lev2 toc-item\"><a href=\"#Linear-Regression-for-Classification-using-Torch\" data-toc-modified-id=\"Linear-Regression-for-Classification-using-Torch-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Linear Regression for Classification using Torch</a></div><div class=\"lev3 toc-item\"><a href=\"#Batch-Gradient-Descent\" data-toc-modified-id=\"Batch-Gradient-Descent-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Batch Gradient Descent</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Torch Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "* **Institution** Pierre & Marie Curie Sorbonne University\n",
    "* **Master DAC** Machine Learning and Deep Learning\n",
    "* **Professors** Patrick Gallinari, Ludovic Denoyer, Nicolas Baskiotis\n",
    "* **Students** : Youcef Benyettou & David Panou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows the instructions given in _\"Guide LUA\"_ written by **Prof. Denoyer** and **Prof. Baskiotis** at UPMC.\n",
    "Its intent is to allow the newcomers to get into LUA parametric models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a nutshell : \n",
    "1. A loss can :\n",
    "    * Can calculate its value by comparing the output for a given input \n",
    "    * Can compute its derivative for a given entry data point\n",
    "2. A module can :\n",
    "    * Can compute it's output for a given input (using its forward method)\n",
    "    * Can update its gradient using its entry value and is delta (i.e the derivative of its error for a given output which is transmitted by the following module  loss)\n",
    "    * Can compute its delta (the derivative of its error compared to ..)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T15:04:42",
     "start_time": "2016-10-01T22:04:42.555Z"
    }
   },
   "source": [
    "## Loading the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T16:34:39",
     "start_time": "2016-10-01T23:34:39.401Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'gnuplot'\n",
    "require 'tools'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T16:34:55",
     "start_time": "2016-10-01T23:34:55.565Z"
    }
   },
   "source": [
    "## Initiallizing default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T17:13:58",
     "start_time": "2016-10-02T00:13:58.565Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- 1: Create a artificial dataset\n",
    "DIMENSION=2 -- Entry dataset features dimensions\n",
    "n_points=1000 -- Number of samples\n",
    "  \n",
    "-- We create two gaussians\n",
    "mean_positive=torch.Tensor(DIMENSION):fill(1); \n",
    "var_positive=1.0\n",
    "\n",
    "mean_negative=torch.Tensor(DIMENSION):fill(-1); \n",
    "var_negative=1.0\n",
    "\n",
    "xs=torch.Tensor(n_points,DIMENSION)\n",
    "ys=torch.Tensor(n_points,1)\n",
    "for i=1,n_points/2 do  xs[i]:copy(torch.randn(DIMENSION)*var_positive+mean_positive); ys[i][1]=1 end\n",
    "for i=n_points/2+1,n_points do xs[i]:copy(torch.randn(DIMENSION)*var_negative+mean_negative); ys[i][1]=-1 end\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T15:07:09",
     "start_time": "2016-10-01T22:07:09.793Z"
    }
   },
   "source": [
    "## Linear Models - Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Models : definition\n",
    "A linear model is defined by the following equation :\n",
    "\n",
    "$$ \\hat{Y} = \\hat{\\beta_{0}} + \\sum_{j=1}^{p}X_{j}*\\hat{\\beta_{j}}$$\n",
    "\n",
    "With the $\\beta$ vector being the model parameters.  This can be noted by the following vector product  : $$ \\hat{Y} = \\beta^T X$$ \n",
    "\n",
    "By design, linear models makes **huge** structural assumption about the data at hand. Thus sometimes, prediction power can be lowered but is very stable.\n",
    "\n",
    "Such a discussion is about the **bias-variance dilemma** that is reminded at the end of this notebook.\n",
    "\n",
    "### Fitting linear model\n",
    "\n",
    "Linear models are usually fitted using the parameter combination that minimize the **Residual Sum of Square** _(RSS)_ parameter.\n",
    "\n",
    "$$ RSS(\\beta) = \\sum_{i=1}^{N}(y_{i}-x^{T}_{i}\\beta)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression for Classification using Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T17:40:31",
     "start_time": "2016-10-02T00:40:31.068Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- 2 : Creation of the model\n",
    "model = nn.Linear(2,1)\n",
    "criterion = nn.MSECriterion()\n",
    "model:zeroGradParameters() -- Here, we are setting the cummulative of the gradients parameters to be equal to 0\n",
    "model:reset() -- I don't know what this command is for but it was in the TP TODO : Look for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Gradient Descent is an optimization method that is using several simple points of the data to optimize a given Loss function, as opposed to Stochastic Gradient Descent that only use single-sample points.\n",
    "\n",
    "**Pro**\n",
    "\n",
    "The benefit of batch gradient descent is that the trajectory of the weight vector is smoothed, compared to that in corresponding single-sample algorithms , since at each update the full set of misclassified patterns is used, the local statistical variations in the misclassified patterns tend to cancel while the large-scale trend does not.\n",
    "\n",
    "Thus, if the samples are linearly separable, all of the possible correction vectors form a linearly separable set, and if Î·(k) satisfies. The sequence of weight vectors produced by the gradient descent algorithm for will always converge to a solution vector.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "On the other side, if the algorithm is to be used in an online (and by online, we mean *REAL* online) manner, then fixed size batch can't be used since frequency of new samples arrival is to be determined.\n",
    "\n",
    "It has to be reminded that Batch doesn't treat data points has a TimeSeries but in a iid manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T18:00:55",
     "start_time": "2016-10-02T01:00:55.088Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- 3 : Learning Loop\n",
    "learning_rate= torch.random(1,10)/10000 -- We put a random weight parameter in this.\n",
    "maxEpoch = 50\n",
    "all_losses={}\n",
    "all_losses[\"stochastic\"]= {}\n",
    "all_losses[\"batch\"]= {}\n",
    "model:zeroGradParameters()\n",
    "\n",
    "for iteration=1,maxEpoch do\n",
    "    loss=0\n",
    "    model:forward(xs)\n",
    "    loss=criterion:forward(output,ys)\n",
    "    model:backward(xs,criterion:backward(output,ys))\n",
    "    updated_parameters = model:updateParameters(learning_rate)\n",
    "    all_losses['batch'][iteration] = loss\n",
    "end\n",
    "\n",
    "--gnuplot.plot(torch.Tensor(all_losses['stochastic'])) \n",
    "gnuplot.plot(torch.Tensor(all_losses['batch'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T18:00:35",
     "start_time": "2016-10-02T01:00:35.676Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  batch : \n",
       "    {\n"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      1 : 3.5892947504199\n",
       "      2 : 3.5854547499488\n",
       "      3 : 3.5777839570721\n",
       "      4 : 3.5663007657187\n",
       "      5 : 3.5510327113318\n",
       "      6 : 3.5320164044777\n",
       "      7 : 3.5092974425746\n",
       "      8 : 3.4829302999542\n"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      9 : 3.4529781965211\n",
       "      10 : 3.4195129453283\n",
       "      11 : 3.3826147794355\n",
       "      12 : 3.3423721584706\n",
       "      13 : 3.2988815553588\n",
       "      14 : 3.2522472237377\n",
       "      15 : 3.2025809466173\n",
       "      16 : 3.1500017668943\n",
       "      17 : 3.0946357003697\n",
       "      18 : 3.0366154319642\n",
       "      19 : 2.9760799958658\n",
       "      20 : 2.9131744403792\n",
       "      21 : 2.8480494782906\n",
       "      22 : 2.780861123589\n",
       "      23 : 2.7117703154234\n",
       "      24 : 2.6409425302035\n",
       "      25 : 2.5685473827806\n",
       "      26 : 2.4947582176728\n",
       "      27 : 2.4197516913208\n",
       "      28 : 2.3437073463836\n",
       "      29 : 2.2668071791025\n",
       "      30 : 2.1892352007785\n",
       "      31 : 2.1111769944207\n"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      32 : 2.0328192676386\n",
       "      33 : 1.9543494028559\n",
       "      34 : 1.8759550059339\n",
       "      35 : 1.7978234542925\n",
       "      36 : 1.7201414456227\n",
       "      37 : 1.6430945482768\n",
       "      38 : 1.5668667544252\n",
       "      39 : 1.491640037057\n",
       "      40 : 1.4175939118943\n",
       "      41 : 1.3449050052778\n",
       "      42 : 1.2737466290676\n",
       "      43 : 1.2042883635843\n",
       "      44 : 1.1366956495986\n",
       "      45 : 1.0711293903527\n"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "      46 : 1.0077455645754\n",
       "      47 : 0.94669485142475\n",
       "      48 : 0.88812226826195\n",
       "      49 : 0.83216682213306\n",
       "      50 : 0.77896117579735\n",
       "    }\n",
       "  stochastic : table: 0x0f1ed8d0\n",
       "}\n"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T16:46:45",
     "start_time": "2016-10-01T23:46:45.413Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = torch.Tensor(50,1)\n",
    "for i=1,50 do Y[i]=i end\n",
    "x = torch.Tensor(50,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-10-01T16:49:59",
     "start_time": "2016-10-01T23:49:59.634Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:613: bad argument #2 to 'format' (number expected, got userdata)\nstack traceback:\n\t[C]: in function 'format'\n\t...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:613: in function 'gnuplot_string'\n\t...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:835: in function 'gnulplot'\n\t...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:976: in function 'f'\n\t[string \"local f = function() return gnuplot.plot(Y,to...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/david/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/david/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010eaa4bd0",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:613: bad argument #2 to 'format' (number expected, got userdata)\nstack traceback:\n\t[C]: in function 'format'\n\t...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:613: in function 'gnuplot_string'\n\t...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:835: in function 'gnulplot'\n\t...rs/david/torch/install/share/lua/5.1/gnuplot/gnuplot.lua:976: in function 'f'\n\t[string \"local f = function() return gnuplot.plot(Y,to...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/david/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/david/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010eaa4bd0"
     ]
    }
   ],
   "source": [
    "gnuplot.plot(Y,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
